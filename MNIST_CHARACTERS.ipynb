{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec51822c",
   "metadata": {},
   "source": [
    "# Aquire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bab2c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emnist\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a872d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    X, Y = emnist.extract_training_samples('letters')\n",
    "    X_test, Y_test = emnist.extract_test_samples('letters')\n",
    "\n",
    "    return X, Y- 1, X_test, Y_test - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ff0e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, X_test, Y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "208caa5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124800, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "831c76e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor(np.array(X))\n",
    "X_test = torch.Tensor(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "442c4d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2868208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7055/2607214113.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y = torch.tensor(Y1, dtype=torch.long)\n",
      "/tmp/ipykernel_7055/2607214113.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Y_test = torch.tensor(Y_test, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "index = torch.tensor(Y, dtype=torch.int64)\n",
    "index = torch.unsqueeze(index, 1)\n",
    "Y1 = torch.zeros(m, 26, dtype=index.dtype).scatter(1, index, value=1)\n",
    "Y = torch.tensor(Y1, dtype=torch.long)\n",
    "index2 = torch.tensor(Y_test, dtype=torch.int64)\n",
    "index2 = torch.unsqueeze(index2, 1)\n",
    "Y_test = torch.zeros(X_test.shape[0], 26, dtype=index2.dtype).scatter(1, index2, value=1)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249ad6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X, Y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e40f7355",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(i):\n",
    "    plt.imshow(i,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6e67f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_img(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "afe99c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8571bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28,512)\n",
    "        self.fc2 = nn.Linear(512,120)\n",
    "        self.fc3 = nn.Linear(120,26)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.flatten(start_dim = 0 if len(x.shape) < 3 else 1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.softmax(self.fc3(x),dim=0)\n",
    "        return x\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "226509bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#constants \n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "07537694",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de792e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "546fad6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(19)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "121b3e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (int dim, torch.dtype dtype)\n * (name dim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [36]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m      6\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m----> 7\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/functional.py:1818\u001b[0m, in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1816\u001b[0m     dim \u001b[38;5;241m=\u001b[39m _get_softmax_dim(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim(), _stacklevel)\n\u001b[1;32m   1817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1818\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1819\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1820\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(dim, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[0;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (int dim, torch.dtype dtype)\n * (name dim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    size = len(train_dataloader.dataset)\n",
    "    for batch, (x, y) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "print('training finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
